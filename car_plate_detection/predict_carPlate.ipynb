{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd70f09-cc4b-43d1-bcea-27c6c6bc7d11",
   "metadata": {},
   "source": [
    "# Car Plate Prediction\n",
    "- This program use the haar_carplate model that created before to get the portion of the car plate from a picture.\n",
    "- To use this prediction, you can change the picture inside predictPlate_sr and run the whole program again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c416491f-9d97-4e2a-8a40-8e2e7185a559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import shutil, os\n",
    "from time import sleep\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import pyocr\n",
    "import pyocr.builders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263b7e8-f795-445d-abdf-e029323edb0e",
   "metadata": {},
   "source": [
    "## Initial Picture Size Conversion\n",
    "This program will convert the picture inside predictPlate_sr to the size only 300x225."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7695ada2-a6e1-4d89-ad4d-2eb0f106fab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictPlate_srdirectory: \n",
      "Start conversion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/gh1b88712ls8_52kt29w8ffw0000gn/T/ipykernel_1792/3726675522.py:17: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img_new = img.resize((300, 225), PIL.Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish conversion.\n"
     ]
    }
   ],
   "source": [
    "# function to empty the directory\n",
    "def emptydir(dirname):\n",
    "    if os.path.isdir(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "        sleep(2)\n",
    "    os.mkdir(dirname)\n",
    "\n",
    "# function to cenversie the picture size\n",
    "def dirResize(src, dst):\n",
    "    myfiles = glob.glob(src + '/*.jpg')\n",
    "    emptydir(dst)\n",
    "    print(src + 'directory: ')\n",
    "    print('Start conversion...')\n",
    "    for f in myfiles:\n",
    "        fname = f.split('/')[-1]\n",
    "        img = Image.open(f)\n",
    "        img_new = img.resize((300, 225), PIL.Image.ANTIALIAS)\n",
    "        img_new.save(dst + '/' + fname)\n",
    "    print('Finish conversion.')\n",
    "    \n",
    "dirResize('predictPlate_sr','predictPlate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e79cc2-de9d-4b89-82a1-88580e008f6d",
   "metadata": {},
   "source": [
    "## Crop the car plate rectangle from the picture\n",
    "We use the car plate model that we created before (haar_carplate.xml) to mark the car plate from the picture, and using it to crop out from the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51e71dc3-fd33-4fcf-8b84-ce731030e704",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cropping car plate...\n",
      "These are the picture cannot be cropped: \n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x16461C310>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573AA9D0>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A84D0>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A8C50>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A8AD0>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A8610>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A8AD0>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573AAF50>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A8850>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A9750>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A9A50>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A96D0>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573A9E50>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573AA4D0>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x225 at 0x1573AAAD0>\n",
      "Finish cropping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/gh1b88712ls8_52kt29w8ffw0000gn/T/ipykernel_1792/2094509431.py:18: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image3 = image2.resize((140,40), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "print('Start cropping car plate...')\n",
    "print('These are the picture cannot be cropped: ')\n",
    "dstdir = 'cropPlate'\n",
    "emptydir(dstdir)\n",
    "myfiles = glob.glob(\"predictPlate/*.jpg\")\n",
    "for imgname in myfiles:\n",
    "    filename = (imgname.split('/'))[-1]\n",
    "    img = cv2.imread(imgname)\n",
    "    \n",
    "    # use model to detect the car plate\n",
    "    detector = cv2.CascadeClassifier('haar_carplate.xml')\n",
    "    signs = detector.detectMultiScale(img, scaleFactor = 1.1, minNeighbors = 4, minSize = (20,20))\n",
    "    \n",
    "    if len(signs) > 0:\n",
    "        for (x,y,w,h) in signs:\n",
    "            image1 = Image.open(imgname)\n",
    "            image2 = image1.crop((x,y,x+w,y+h))\n",
    "            image3 = image2.resize((140,40), Image.ANTIALIAS) \n",
    "            img_gray = np.array(image3.convert('L')) # convert to gray \n",
    "            _, img_thre = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY) # convert grey to black white\n",
    "            cv2.imwrite(dstdir + '/' + filename, img_thre)\n",
    "    \n",
    "    else: \n",
    "        print(filename)\n",
    "         \n",
    "print('Finish cropping.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745110a-4643-4091-b3b3-592c60e98664",
   "metadata": {},
   "source": [
    "# Testing OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df7cfdf7-04b4-4228-a4c1-d228cb022103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyocr==0.7.2\n",
      "  Downloading pyocr-0.7.2.tar.gz (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /Users/chunlingtan/anaconda3/lib/python3.11/site-packages (from pyocr==0.7.2) (9.4.0)\n",
      "Building wheels for collected packages: pyocr\n",
      "  Building wheel for pyocr (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyocr: filename=pyocr-0.7.2-py3-none-any.whl size=36638 sha256=a5875d53338a4f842fcf8c066415d9064f379403ad00f00f2dca35d4b886b099\n",
      "  Stored in directory: /Users/chunlingtan/Library/Caches/pip/wheels/78/d1/d6/d086e7039ee8751e97e9ca7cac59ca10de1feda46de3e04a00\n",
      "Successfully built pyocr\n",
      "Installing collected packages: pyocr\n",
      "Successfully installed pyocr-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyocr==0.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b74a285e-341a-446e-b339-8ec34e6180b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result= 113011\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "import pyocr\n",
    "import pyocr.builders\n",
    "\n",
    "tools = pyocr.get_available_tools()\n",
    "if len(tools) == 0:\n",
    "    print(\"No OCR tool found\")\n",
    "    sys.exit(1)\n",
    "tool = tools[0]  \n",
    "\n",
    "txt = tool.image_to_string(\n",
    "    Image.open('test.jpg'),\n",
    "    builder=pyocr.builders.TextBuilder()\n",
    ")\n",
    "print(\"result=\",txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e939cc7-e711-4d15-8899-243814438e47",
   "metadata": {},
   "source": [
    "# Optical Character Recognition\n",
    "\n",
    "- Using Tesseract to detect the character\n",
    "- download using command: 'brew install tesseract'\n",
    "- I also explain all the thing inside 7238N2.ipynb, you can refer to it if don't understand the concept.\n",
    "- the result is write inside the resutls.txt by using the carPlate directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4cda45e-6b48-409b-afcf-24e08c8c2911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocr detection result： 7569 YM\n",
      "After optimization：7569YM   filename：7569YM.jpg  result:V\n",
      "ocr detection result： AKW 6596,\n",
      "After optimization：AKW6596   filename：AKW6596.jpg  result:V\n",
      "ocr detection result： 9060 J5\n",
      "After optimization：9060J5   filename：9060J5.jpg  result:V\n",
      "ocr detection result： 1923 LM\n",
      "After optimization：1923LM   filename：1923LM.jpg  result:V\n",
      "ocr detection result： 3322 NH\n",
      "After optimization：3322NH   filename：3322NH.jpg  result:V\n",
      "ocr detection result： AKK7771\n",
      "After optimization：AKK7771   filename：AKK7771.jpg  result:V\n",
      "ocr detection result： AGC 7052\n",
      "After optimization：AGC7052   filename：AGC7052.jpg  result:V\n",
      "ocr detection result： 0655 VN\n",
      "After optimization：0655VN   filename：0655VN.jpg  result:V\n",
      "ocr detection result： AGK 3379\n",
      "After optimization：AGK3379   filename：AGK3379.jpg  result:V\n",
      "ocr detection result： AHH 9997\n",
      "After optimization：AHH9997   filename：AHH9997.jpg  result:V\n",
      "ocr detection result： 1710YC\n",
      "After optimization：1710YC   filename：1710YC.jpg  result:V\n",
      "ocr detection result： 3M 6605\n",
      "After optimization：3M6605   filename：3M6605.jpg  result:V\n",
      "ocr detection result： 6508 ZJ\n",
      "After optimization：6508ZJ   filename：6508ZJ.jpg  result:V\n",
      "ocr detection result： AXN 6501\n",
      "After optimization：AXN6501   filename：AXN6051.jpg  result:X\n",
      "ocr detection result： ACC 7558\n",
      "After optimization：ACC7558   filename：ACC7558.jpg  result:V\n"
     ]
    }
   ],
   "source": [
    "def area(row, col):\n",
    "    global nn\n",
    "    if bg[row][col] != 255:\n",
    "        return\n",
    "    bg[row][col] = lifearea \n",
    "    if col>1: # left\n",
    "        if bg[row][col-1]==255:\n",
    "            nn +=1\n",
    "            area(row,col-1)\n",
    "    if col< w-1: # right\n",
    "        if bg[row][col+1]==255:\n",
    "            nn +=1\n",
    "            area(row,col+1)             \n",
    "    if row>1: # up\n",
    "        if bg[row-1][col]==255:\n",
    "            nn+=1            \n",
    "            area(row-1,col)\n",
    "    if row<h-1: # down\n",
    "        if bg[row+1][col]==255:\n",
    "            nn+=1            \n",
    "            area(row+1,col)       \n",
    "\n",
    "myfiles = glob.glob('cropPlate/*.jpg')\n",
    "\n",
    "with open('results.txt', 'w') as f:\n",
    "    for file in myfiles:\n",
    "\n",
    "        # read the image and change to the color of the image\n",
    "        image = cv2.imread(file)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "        _,thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV) \n",
    "        # find contours\n",
    "        contours1 = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = contours1[0]   \n",
    "\n",
    "        # get the image position and put inside a list\n",
    "        letter_image_regions = [] \n",
    "        for contour in contours:  \n",
    "            (x, y, w, h) = cv2.boundingRect(contour) \n",
    "            letter_image_regions.append((x, y, w, h)) \n",
    "        letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])  \n",
    "\n",
    "        # Calculate the total number of car plate (here should be 6)\n",
    "        count=0 \n",
    "        for box in letter_image_regions:  \n",
    "            x, y, w, h = box        \n",
    "            # inside the region\n",
    "            if x>=2 and x<=125 and w>=5 and w<=26 and h>=20 and h<40:\n",
    "                count +=1   \n",
    "\n",
    "        # if not, then maybe two words is together, we add the width\n",
    "        if count<6: \n",
    "            wmax=35\n",
    "        else:\n",
    "            wmax=26\n",
    "\n",
    "        # save the letter position to the letterlist based on the wmax\n",
    "        nChar=0 \n",
    "        letterlist = [] \n",
    "        for box in letter_image_regions:  \n",
    "            x, y, w, h = box        \n",
    "            if x>=2 and x<=125 and w>=5 and w<=wmax and h>=20 and h<40:\n",
    "                nChar +=1 \n",
    "                letterlist.append((x, y, w, h)) \n",
    "\n",
    "\n",
    "        # remove noise (see 7238N2.ipynb and Life.ipynb) \n",
    "        for i in range(len(thresh)):  \n",
    "            for j in range(len(thresh[i])): \n",
    "                if thresh[i][j] == 255:     \n",
    "                    count = 0 \n",
    "                    for k in range(-2, 3):\n",
    "                        for l in range(-2, 3):\n",
    "                            try:\n",
    "                                if thresh[i + k][j + l] == 255: \n",
    "                                    count += 1\n",
    "                            except IndexError:\n",
    "                                pass\n",
    "                    if count <= 6:  \n",
    "                        thresh[i][j] = 0          \n",
    "\n",
    "        # remove abnormal ground (see 7238N2_example.ipynb and Life.ipynb)\n",
    "        real_shape=[]\n",
    "        for i,box in enumerate(letterlist):  \n",
    "            x, y, w, h = box        \n",
    "            bg=thresh[y:y+h, x:x+w]\n",
    "\n",
    "            # since we have remove the noise, we can just check the first and last number to see if have abnormal ground\n",
    "            if i==0 or i==nChar: \n",
    "                lifearea=0 \n",
    "                nn=0       \n",
    "                life=[]   \n",
    "\n",
    "                # find lifearea\n",
    "                for row in range(0,h):\n",
    "                    for col in range(0,w):\n",
    "                      if bg[row][col] == 255:\n",
    "                          nn = 1  \n",
    "                          lifearea = lifearea + 1  \n",
    "                          area(row,col)  \n",
    "                          life.append(nn)\n",
    "\n",
    "                # retrieve max life\n",
    "                maxlife=max(life) \n",
    "                indexmaxlife=life.index(maxlife)           \n",
    "\n",
    "                # change other to bg 0\n",
    "                for row in range(0,h):\n",
    "                    for col in range(0,w):\n",
    "                      if bg[row][col] == indexmaxlife+1:\n",
    "                          bg[row][col]=255\n",
    "                      else:\n",
    "                          bg[row][col]=0         \n",
    "\n",
    "            real_shape.append(bg)\n",
    "\n",
    "\n",
    "            # we need to add some white space such that the OCR can detect\n",
    "            image2=thresh.copy()\n",
    "            newH, newW = image2.shape    \n",
    "            space = 10  \n",
    "            bg = np.zeros((newH+space*2, newW+space*2+20, 1), np.uint8)  \n",
    "            bg.fill(0)  \n",
    "\n",
    "            for i,letter in enumerate(real_shape):\n",
    "                h=letter.shape[0]   # initial height and widet\n",
    "                w=letter.shape[1]\n",
    "                x=letterlist[i][0]  # initial position\n",
    "                y=letterlist[i][1]\n",
    "\n",
    "                # add the letter to the picture\n",
    "                for row in range(h):\n",
    "                    for col in range(w):\n",
    "                        bg[space+y+row][space+x+col+i*3] = letter[row][col] \n",
    "\n",
    "            _,bg = cv2.threshold(bg, 127, 255, cv2.THRESH_BINARY_INV)              \n",
    "            cv2.imwrite('result.jpg', bg)           \n",
    "\n",
    "        # OCR to recognize the car palte\n",
    "        tools = pyocr.get_available_tools()\n",
    "        if len(tools) == 0:\n",
    "            print(\"No OCR tool found\")\n",
    "            sys.exit(1)\n",
    "        tool = tools[0]  \n",
    "\n",
    "        result = tool.image_to_string(\n",
    "            Image.open('result.jpg'),\n",
    "            builder=pyocr.builders.TextBuilder()\n",
    "        )\n",
    "\n",
    "        # optimize the OCR result\n",
    "        txt=result.replace(\"!\",\"1\") \n",
    "        real_txt=re.findall(r'[A-Z]+|[\\d]+',txt) # only collect the number and uppercase characters\n",
    "\n",
    "        # combine the text together\n",
    "        txt_Plate=\"\" \n",
    "        for char in real_txt:\n",
    "            txt_Plate += char\n",
    "        print(\"ocr detection result：\", result)\n",
    "        basename=os.path.basename(file)\n",
    "        if basename.split(\".\")[0]==txt_Plate:\n",
    "            mess=\"V\"\n",
    "        else:\n",
    "            mess=\"X\"                         \n",
    "        print(\"After optimization：{}   filename：{}  result:{}\".format(txt_Plate,basename,mess))\n",
    "\n",
    "        f.write(\"OCR detection result: {}\\n\".format(result))\n",
    "        basename = os.path.basename(file)\n",
    "        if basename.split(\".\")[0] == txt_Plate:\n",
    "            mess = \"V\"\n",
    "        else:\n",
    "            mess = \"X\"                         \n",
    "        f.write(\"After optimization: {}   filename: {}  result: {}\\n\".format(txt_Plate, basename, mess))\n",
    "\n",
    "\n",
    "\n",
    "        # cv2.imshow('image', image)     \n",
    "        # cv2.imshow('bg', bg)           \n",
    "        # cv2.moveWindow(\"image\",500,250)\n",
    "        # cv2.moveWindow(\"bg\",500,350)     \n",
    "        # key = cv2.waitKey(0)           \n",
    "        # cv2.destroyAllWindows()\n",
    "        # if key == 113 or key==81:  \n",
    "        #     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
